{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference Target Propagation\n",
    "---\n",
    "In this notebook, we will use an interesting neural network that learns via **target propagation** to classify images from the CIFAR-10 database. Note that we provide a number of instructions (including code and descriptions) for the ease of your learning. Be free to change the provided code if you want but in this case you should explain your motivation in the submitted report.\n",
    "\n",
    "\n",
    "Our aim is to reproduce the results of the paper entitled \"Difference Target Propagation\" （ https://arxiv.org/abs/1412.7525 ） on the CIFAR-10 database. Before completing this work, you are required to carefully read the paper and understand its basic idea about the proposed learning strategy. \n",
    "\n",
    "\n",
    "![](model.png)\n",
    "\n",
    "Figure 1. The Schematic overview of the target propagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for CUDA\n",
    "\n",
    "Since these are larger (32x32x3) images, it may prove useful to speed up your training time by using a GPU. CUDA is a parallel computing platform and CUDA Tensors are the same as typical Tensors, only they utilize GPU's for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the Data\n",
    "\n",
    "If you're not familiar with the Cifar-10, you may find it useful to look at: http://www.cs.toronto.edu/~kriz/cifar.html . \n",
    "\n",
    "A copy of the data is also placed on the class website.  \n",
    "\n",
    "#### TODO: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: load the data   #\n",
    "#############################################################################\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size=1024\n",
    "\n",
    "transform=transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "full_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "train_length = int(full_dataset.__len__()*0.8)\n",
    "val_length = full_dataset.__len__() - train_length\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_length, val_length])\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0)\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE               #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the Network Architecture\n",
    "\n",
    "Here, you'll define a neural network named DTPNet, whose architecture resembles multiple layer perceptron (MLP) but adopts target propagation for parameter updating. You may use the following Pytorch functions to build it.\n",
    "\n",
    "* [Linear transformation layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "* [Non-linear activations](https://pytorch.org/docs/stable/generated/torch.tanh.html)\n",
    "* [Gradient computing operation](https://pytorch.org/docs/stable/autograd.html?highlight=torch%20autograd%20grad#torch.autograd.grad)\n",
    "\n",
    "\n",
    "### TODO: \n",
    "#### 1)  Define DTPNet: Completing the __init__ function\n",
    "**Sizes of the hidden layers**: As the MLP takes a vector as input (ignoring the dimension of the batch), we should transform the image to a vector, whose dimension should be 3072 ($ 32\\times 32\\times 3 $)。 We suggest that the network architecture was 3072-1000-1000-1000-10. In each layer, the network uses the hyperbolic tangent as the activation function. You can also design these hyperparameters on your own.\n",
    "\n",
    " HINT: because we will compute the loss and gradient for each layer instead of chain rule, you might want to build a separate computational graph for each layer. Think of how to do this.\n",
    "#### 2)  Define the forward path of DTPNet: Completing the \"forward\" function\n",
    "The forward path involves computing unit values for all layers, that is,\n",
    "\n",
    "\\begin{align}\n",
    "\\text{for } i&=  \\text{1 to } M \\\\\n",
    " & h_i \\leftarrow f_i(h_{i-1})\n",
    "\\end{align}\n",
    "where $f_i$ stands for the transformation layer of the DTPNet. Please refer to the original paper for more information.\n",
    "\n",
    "#### 3)  Define the backward path of DTPNet: Completing the \"backward\" function\n",
    "The computational details of the backward path are described in Algorithm 1 of the paper. It involves computing the targets, calculating the loss and calculate the gradients for each of the layers in the neural network in a top-down manner. \n",
    "\n",
    "To make the code more readable, you need first define the \"backward\" function will call ``compute_target`` and ``reconstruction`` function.\n",
    "\n",
    "**Important:** The basic idea of the strategy to update the parameter for each layer are presented in the following section. You may need it for completing this function.\n",
    "\n",
    "##### 3.1)  Calculate the targets for each layer\n",
    "For the target of the highest layer, it is computed by\n",
    "$\\hat{\\mathbf{h}}_{M-1} \\leftarrow \\mathbf{h}_{M-1} - \\hat{\\eta} \\frac {\\partial L} {\\partial \\mathbf{h}_{M-1}}$, \\; ($L$ is the global loss)\n",
    "\n",
    "For the targets of the lower layers, they are computed by\n",
    "\\begin{align}\n",
    "\\text{for } i&=  M-1 \\text{ to } 2 \\\\\n",
    "& \\hat{\\mathbf{h}}_{i-1} \\leftarrow \\mathbf{h}_{i-1} - g_i(\\mathbf{h}_{i}) +  g_i(\\hat{\\mathbf{h}}_{i})\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "##### 3.2) Implement the reconstruction function \n",
    "The reconstruction function involves $g_i(f_i(\\mathbf{h}_{i-1}))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_model: {'F1': Linear(in_features=3072, out_features=1000, bias=True), 'F2': Linear(in_features=1000, out_features=1000, bias=True), 'F3': Linear(in_features=1000, out_features=1000, bias=True), 'F4': Linear(in_features=1000, out_features=10, bias=True)}\n",
      "backward_model: {'G2': Linear(in_features=1000, out_features=1000, bias=True), 'G3': Linear(in_features=1000, out_features=1000, bias=True)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#Define a MLP\n",
    "class DTPNet(nn.Module):\n",
    "    def __init__(self,hidden_sizes=None):\n",
    "        super(DTPNet, self).__init__()\n",
    "        # construct the network\n",
    "        #############################################################################\n",
    "        self.num_layers=len(hidden_sizes)-1\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        \n",
    "        self.forward_model=dict()\n",
    "        self.forward_optim=dict()\n",
    "        for i in range(self.num_layers):\n",
    "            self.forward_model['F{}'.format(i+1)]=nn.Linear(in_features=hidden_sizes[i],out_features=hidden_sizes[i+1]).to(device)\n",
    "            self.forward_optim['F{}'.format(i+1)]=optim.RMSprop(params=self.forward_model['F{}'.format(i+1)].parameters(), lr=0.01)\n",
    "        \n",
    "        self.backward_model=dict()\n",
    "        self.backward_optim=dict()\n",
    "        for i in range(1,self.num_layers-1):\n",
    "            self.backward_model['G{}'.format(i+1)]=nn.Linear(in_features=hidden_sizes[i+1],out_features=hidden_sizes[i]).to(device)\n",
    "            self.backward_optim['G{}'.format(i+1)]=optim.RMSprop(params=self.backward_model['G{}'.format(i+1)].parameters(), lr=0.01)\n",
    "        #############################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Input: a batch of images, the size is [batchsize, 3072]\n",
    "        #Output:the values of each layer in the network\n",
    "        values = dict()\n",
    "        #############################################################################\n",
    "        for i,k in enumerate(self.forward_model):\n",
    "            if i==self.num_layers-1:\n",
    "                x=torch.softmax(self.forward_model[k](x),dim=-1)\n",
    "            else:\n",
    "                x=torch.tanh(self.forward_model[k](x))\n",
    "            values['H{}'.format(i+1)]=x        \n",
    "        #############################################################################\n",
    "        return values\n",
    "    \n",
    "    #以下函数定义有修改，详见实验报告\n",
    "    def backward(self, values, global_loss):\n",
    "        targets=self.compute_target(values, global_loss)\n",
    "\n",
    "        loss_inv=self.compute_loss_inv(values)\n",
    "        loss=self.compute_loss(values,targets,global_loss)\n",
    "        \n",
    "        for key in loss_inv.keys():\n",
    "            grad=torch.autograd.grad(loss_inv[key], self.backward_model[key].parameters(), retain_graph = True)\n",
    "            self.backward_model[key].weight.grad=grad[0]\n",
    "            self.backward_model[key].bias.grad=grad[1]\n",
    "        for key in loss.keys():\n",
    "            grad=torch.autograd.grad(loss[key], self.forward_model[key].parameters(), retain_graph = True)\n",
    "            self.forward_model[key].weight.grad=grad[0]\n",
    "            self.forward_model[key].bias.grad=grad[1]\n",
    "\n",
    "        for key in loss_inv.keys():\n",
    "            self.backward_optim[key].step()\n",
    "        for key in loss.keys():\n",
    "            self.forward_optim[key].step()\n",
    "\n",
    "    def compute_target(self, values, global_loss):\n",
    "       #Input: values=[value_1,value_2,...,value_N]: the values of each layer (totally N layers) in the network\n",
    "        #Output: loss=[target_1,target_2,...,target_N]: the targets of each layer (totally N layers) in the network\n",
    "        targets  = dict() \n",
    "        lr0=0.327736332653       \n",
    "        targets['H{}_'.format(self.num_layers-1)]=values['H{}'.format(self.num_layers-1)]-lr0*torch.autograd.grad(global_loss, values['H{}'.format(self.num_layers-1)], retain_graph = True)[0]\n",
    "        for i in range(self.num_layers-1,1,-1):\n",
    "            targets['H{}_'.format(i-1)]=values['H{}'.format(i-1)]-self.backward_model['G{}'.format(i)](values['H{}'.format(i)])+self.backward_model['G{}'.format(i)](targets['H{}_'.format(i)])      \n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def compute_loss(self, values, targets, global_loss):\n",
    "        loss=dict()\n",
    "\n",
    "        for i in range(self.num_layers-1):\n",
    "            loss['F{}'.format(i+1)]=self.criterion(values['H{}'.format(i+1)],targets['H{}_'.format(i+1)])\n",
    "        loss['F{}'.format(self.num_layers)]=global_loss\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss_inv(self, values):\n",
    "        #Input: values=[value_1,value_2,...,value_N]: the values of each layer (totally N layers) in the network\n",
    "        #output: loss=[value_2,...,value_N-1]: the reconstructed values of each layer (totally N layers) in the network\n",
    "        loss_inv = dict()\n",
    "        c=0.359829566008\n",
    "        for i in range(self.num_layers-1,1,-1):\n",
    "            temp=torch.randn(values['H{}'.format(i-1)].shape).to(device)*(c**1/2)+values['H{}'.format(i-1)]\n",
    "            loss_inv['G{}'.format(i)]=self.criterion(self.backward_model['G{}'.format(i)](self.forward_model['F{}'.format(i)](temp)),temp)\n",
    "\n",
    "        return loss_inv\n",
    "    \n",
    "    def set_train(self):\n",
    "        for key in self.forward_model.keys():\n",
    "            self.forward_model[key].train()\n",
    "        for key in self.backward_model.keys():\n",
    "            self.backward_model[key].train()     \n",
    "    \n",
    "    def set_eval(self):\n",
    "        for key in self.forward_model.keys():\n",
    "            self.forward_model[key].eval()\n",
    "        for key in self.backward_model.keys():\n",
    "            self.backward_model[key].eval() \n",
    "\n",
    "model = DTPNet([3072,1000,1000,1000,10])\n",
    "print('forward_model:',model.forward_model)#用字典定义模型层，打印模型层\n",
    "print('backward_model:',model.backward_model)#用字典定义模型层，打印模型层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) \n",
    "\n",
    "Before the training process, you need to first specify your the loss function. For example, we set the negative log-likelihood as the the global loss of the image classification task. \n",
    "\n",
    "#### TODO: Define the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: define the loss function           #\n",
    "#############################################################################\n",
    "global_loss_fn=torch.nn.NLLLoss()\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE               #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Network\n",
    "The details of the training phrase of DTPNet can be found in Algorithm 1 of the paper, which is also posted here for your convenience.  Please note that the training process of DTPNet is dramatically different from the traditional neural network. The main difference is that back-propagation uses chain rule to update parameters and the DTP calculates the targets and updates parameters layer by layer. Thus, so you can use the \"detach\" function in Pytorch to truncate the gradients to avoid auto-differetiation.\n",
    "\n",
    "Hint: Instead using the backpropagation algorithm, we calculate the loss and then calculate the gradients for each layer, then we can use the gradients for each layer to update the parameters for each layer.\n",
    "## Examples to show how to update parameters of a single layer by Pytorch\n",
    "There are two approaches to derive the gradients for the parameters of a neural network, namely, the optimizer module and autograd.grad() function. You can choose one of them or both of them to accomplish this work. Below, we will elaborate them in detail.\n",
    "### 1)  Optimizer\n",
    "The ``optimizer`` module controls the parameter updating for the neural network in Pytorch. We take a single layer of the multiple layer perceptron (MLP) as an example, which is defined by\n",
    "```\n",
    "single_layer = torch.nn.Linear(2,3)\n",
    "```\n",
    "We can build an optimizer via Pytorch.\n",
    "```\n",
    "optimizer = torch.optim.RMSprop([{'params':single_layer.parameters(), 'lr': 1}])\n",
    "```\n",
    "Then we can update the parameters of single_layer by calling the ``step`` function of the optimizer, for example,\n",
    "```\n",
    "x = torch.randn(10,2)\n",
    "y = torch.randn(10,3)\n",
    "predict = single_layer(x)\n",
    "loss = ((predict-y)**2).sum() \n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 2) autograd.grad()\n",
    "This function provides a way for the users to manually obtain the gradients for each of the parameters.\n",
    "```\n",
    "x = torch.randn(10,2)\n",
    "y = torch.randn(10,3)\n",
    "predict = MLP(x)\n",
    "loss = ((predict-y)**2).sum()\n",
    "grad_weight = torch.autograd.grad(loss, MLP.weight, retain_graph = True)[0]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"algo.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "\n",
    "\n",
    "Remember to look at how the training and validation loss decreases over time and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1|Train_loss:-0.331 Eval_loss:-0.339 Train_acc:0.335 Eval_acc:0.341\n",
      "Epoch 2|Train_loss:-0.373 Eval_loss:-0.350 Train_acc:0.378 Eval_acc:0.352\n",
      "Epoch 3|Train_loss:-0.384 Eval_loss:-0.355 Train_acc:0.388 Eval_acc:0.356\n",
      "Epoch 4|Train_loss:-0.391 Eval_loss:-0.360 Train_acc:0.396 Eval_acc:0.362\n",
      "Epoch 5|Train_loss:-0.396 Eval_loss:-0.375 Train_acc:0.402 Eval_acc:0.378\n",
      "Epoch 6|Train_loss:-0.400 Eval_loss:-0.375 Train_acc:0.406 Eval_acc:0.375\n",
      "Epoch 7|Train_loss:-0.405 Eval_loss:-0.363 Train_acc:0.411 Eval_acc:0.364\n",
      "Epoch 8|Train_loss:-0.407 Eval_loss:-0.371 Train_acc:0.413 Eval_acc:0.372\n",
      "Epoch 9|Train_loss:-0.409 Eval_loss:-0.381 Train_acc:0.416 Eval_acc:0.383\n",
      "Epoch 10|Train_loss:-0.413 Eval_loss:-0.380 Train_acc:0.419 Eval_acc:0.378\n",
      "Epoch 11|Train_loss:-0.414 Eval_loss:-0.383 Train_acc:0.421 Eval_acc:0.381\n",
      "Epoch 12|Train_loss:-0.417 Eval_loss:-0.376 Train_acc:0.422 Eval_acc:0.374\n",
      "Epoch 13|Train_loss:-0.418 Eval_loss:-0.380 Train_acc:0.424 Eval_acc:0.381\n",
      "Epoch 14|Train_loss:-0.419 Eval_loss:-0.383 Train_acc:0.426 Eval_acc:0.384\n",
      "Epoch 15|Train_loss:-0.423 Eval_loss:-0.384 Train_acc:0.427 Eval_acc:0.383\n",
      "Epoch 16|Train_loss:-0.424 Eval_loss:-0.384 Train_acc:0.429 Eval_acc:0.384\n",
      "Epoch 17|Train_loss:-0.425 Eval_loss:-0.386 Train_acc:0.431 Eval_acc:0.384\n",
      "Epoch 18|Train_loss:-0.427 Eval_loss:-0.387 Train_acc:0.433 Eval_acc:0.385\n",
      "Epoch 19|Train_loss:-0.429 Eval_loss:-0.381 Train_acc:0.433 Eval_acc:0.378\n",
      "Epoch 20|Train_loss:-0.427 Eval_loss:-0.381 Train_acc:0.434 Eval_acc:0.378\n",
      "Epoch 21|Train_loss:-0.427 Eval_loss:-0.380 Train_acc:0.436 Eval_acc:0.378\n",
      "Epoch 22|Train_loss:-0.431 Eval_loss:-0.385 Train_acc:0.436 Eval_acc:0.385\n",
      "Epoch 23|Train_loss:-0.432 Eval_loss:-0.378 Train_acc:0.437 Eval_acc:0.374\n",
      "Epoch 24|Train_loss:-0.433 Eval_loss:-0.388 Train_acc:0.438 Eval_acc:0.385\n",
      "Epoch 25|Train_loss:-0.435 Eval_loss:-0.376 Train_acc:0.439 Eval_acc:0.371\n",
      "Epoch 26|Train_loss:-0.432 Eval_loss:-0.386 Train_acc:0.440 Eval_acc:0.383\n",
      "Epoch 27|Train_loss:-0.435 Eval_loss:-0.385 Train_acc:0.441 Eval_acc:0.382\n",
      "Epoch 28|Train_loss:-0.435 Eval_loss:-0.385 Train_acc:0.443 Eval_acc:0.381\n",
      "Epoch 29|Train_loss:-0.440 Eval_loss:-0.384 Train_acc:0.443 Eval_acc:0.382\n",
      "Epoch 30|Train_loss:-0.437 Eval_loss:-0.384 Train_acc:0.445 Eval_acc:0.381\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: train and validation              #\n",
    "#############################################################################\n",
    "for epoch in range(30):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_correct_count = 0\n",
    "    model.set_train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs=inputs.to(device)\n",
    "        inputs=inputs.view([inputs.shape[0],3072])\n",
    "        labels=labels.to(device)\n",
    "\n",
    "        values = model(inputs)\n",
    "        outputs = values['H{}'.format(model.num_layers)]\n",
    "        train_correct_count += (torch.argmax(outputs,dim=1)==labels).sum().cpu().item()\n",
    "        global_loss = global_loss_fn(outputs, labels)\n",
    "        model.backward(values,global_loss)\n",
    "        train_loss += global_loss.cpu().item()\n",
    "\n",
    "    train_loss=train_loss/(i+1)\n",
    "    train_acc=train_correct_count/(i+1)/batch_size\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_correct_count = 0\n",
    "    model.set_eval()\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs=inputs.to(device).view(inputs.shape[0],3072)\n",
    "        labels=labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)['H{}'.format(model.num_layers)]\n",
    "        val_correct_count += (torch.argmax(outputs,dim=1)==labels).sum().cpu().item()\n",
    "        global_loss = global_loss_fn(outputs, labels)\n",
    "        val_loss += global_loss.cpu().item()\n",
    "    val_loss=val_loss/(i+1)\n",
    "    val_acc=val_correct_count/(i+1)/batch_size\n",
    "\n",
    "    print('Epoch %d|Train_loss:%.3f Eval_loss:%.3f Train_acc:%.3f Eval_acc:%.3f'%(epoch+1,train_loss,val_loss,train_acc,val_acc))\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE               #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network\n",
    "\n",
    "Test your trained model on previously unseen data and print the test accuracy of each class and the whole! Try your best to get a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test|Class1(plane)-acc=0.48\n",
      "Test|Class2(car)-acc=0.453\n",
      "Test|Class3(bird)-acc=0.246\n",
      "Test|Class4(cat)-acc=0.171\n",
      "Test|Class5(deer)-acc=0.311\n",
      "Test|Class6(dog)-acc=0.339\n",
      "Test|Class7(frog)-acc=0.464\n",
      "Test|Class8(horse)-acc=0.403\n",
      "Test|Class9(ship)-acc=0.561\n",
      "Test|Class10(truck)-acc=0.496\n",
      "\n",
      "Test|Overall-acc=0.39239999999999997\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: test the trained network             #\n",
    "#############################################################################\n",
    "class_count=np.zeros(10,dtype=int)\n",
    "correct_count=np.zeros(10,dtype=int)\n",
    "model.set_eval()\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs=inputs.to(device)\n",
    "    inputs=inputs.view([inputs.shape[0],3072])\n",
    "    outputs = torch.argmax(model(inputs)['H{}'.format(model.num_layers)],dim=1).cpu().item()\n",
    "    class_count[labels]+=1\n",
    "    if outputs==labels:\n",
    "        correct_count[labels]+=1\n",
    "for i in range(10):\n",
    "    print('Test|Class{}('.format(i+1)+classes[i]+')-acc={}'.format(correct_count[i]/class_count[i]))\n",
    "print('\\nTest|Overall-acc={}'.format(np.sum(correct_count/10000)))\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE               #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What are your model's weaknesses during your experiment and how might they be improved?\n",
    "+ 本实验只使用了较为简单的MLP网络，由于网络结构过于简单，最终分类结果较差，仅用作DTP算法是示意。实际上，MLP网络输入时先将图像展开为列向量，这种操作不易获得图像上邻近位置的信息，因而分类效果较差。使用更加复杂的卷积神经网络应当可以达到更好的效果，将卷积神经网络中的一个卷积层或一个卷积块看做一个广义的前向计算函数${f_i}$即可使用DTP算法进行训练。由于任务一中已经验证了ResNet的分类表现，此处不再重复实现。\n",
    "+ DTP算法中涉及较多的超参数选择，如各层局部参数更新的学习率、随机高斯噪声的功率谱密度以及全局损失函数、优化器的选择。在这些超参数上进行进一步调优可能在相同的网络结构上实现更好的测试表现。\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}